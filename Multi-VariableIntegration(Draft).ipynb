{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from pennylane.math import toarray\n",
    "from pennylane import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('toy_data_10e4.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.55258737 0.41757623 2.5810235  0.        ]\n",
      " [1.05945455 2.73902844 2.59982768 0.01002004]\n",
      " [2.71202945 3.38179615 1.0272925  0.02004008]\n",
      " [2.21421541 0.12472855 1.58366213 0.03006012]\n",
      " [1.40135874 2.4821793  0.11875834 0.04008016]]\n",
      "[[1.40135874 2.4821793  0.11875834 0.04008016]\n",
      " [0.16315241 2.51735018 2.47341997 0.0501002 ]\n",
      " [2.42817168 2.90637455 1.44798689 0.06012024]\n",
      " ...\n",
      " [2.26058831 2.62355914 0.18093676 4.97995992]\n",
      " [2.91426381 3.41772047 2.93088925 4.98997996]\n",
      " [0.1022243  2.0529486  1.72946409 5.        ]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "Xdata = data['xdata']\n",
    "print(Xdata[:5])\n",
    "print(Xdata[4:])\n",
    "print(len(Xdata[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03413077  0.00653628 -0.83397146 ...  0.9999308  -0.8789377\n",
      " -0.79724696]\n"
     ]
    }
   ],
   "source": [
    "Ydata = data['ydata']\n",
    "print(Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03413076931141696\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    x3 = x[2]\n",
    "    a0 = x[3]\n",
    "    return np.cos(x1 + 2*x2 + 1/2*x3 + a0)\n",
    "\n",
    "print(f(Xdata[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_stochastic = qml.device(\"lightning.qubit\", wires = 10)\n",
    "\n",
    "@qml.qnode(dev_stochastic)\n",
    "def Ansatz(thetas, phis, x, num_layers):\n",
    "    \"\"\"\n",
    "    Quantum Circuit Model\n",
    "\n",
    "    INPUT\n",
    "    thetas : array of theta parameters (theta_0, theta_1, theta_2, theta_3)\n",
    "    phis : array of phi for the last rotation gate\n",
    "    xdim : dimension of variables\n",
    "    num_layers : layers we will append for the circuit\n",
    "\n",
    "    OUTPUT\n",
    "    Expectation values with PauliZ measure\n",
    "    \"\"\"\n",
    "    \n",
    "    xdim = len(x)\n",
    "    num_qubits = math.ceil(xdim / 2)\n",
    "    idx = 0\n",
    "\n",
    "    params = 0\n",
    "    params += thetas\n",
    "    \n",
    "    param_index = 1\n",
    "    for _ in range(num_layers):\n",
    "        for j in range(xdim):\n",
    "            params[param_index] = thetas[param_index] * x[j]\n",
    "            param_index += 5\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        k = 0\n",
    "        for i in range(xdim):\n",
    "            qml.RY(params[idx], wires = int(k))\n",
    "            qml.RZ(params[idx+1], wires = int(k), id = f'x{i}')\n",
    "            qml.RZ(params[idx+2], wires = int(k))\n",
    "            qml.RY(params[idx+3], wires = int(k))\n",
    "            qml.RZ(params[idx+4], wires = int(k))\n",
    "            idx += 5\n",
    "            k+=1/2\n",
    "\n",
    "        if num_qubits > 1:\n",
    "            for q in range(0,num_qubits-1,1):\n",
    "                qml.CZ([q, q+1])\n",
    "            if num_qubits > 2:\n",
    "                qml.CZ([num_qubits-1, 0])\n",
    "    \n",
    "    if num_qubits > 1:\n",
    "            for i in range(num_qubits):\n",
    "                qml.RY(phis[i], wires=i, id = f\"phi{i}\")\n",
    "    \n",
    "    obs = qml.PauliZ(0)\n",
    "    for i in range(num_qubits-1):\n",
    "         obs = obs @ qml.PauliZ(i+1)\n",
    "\n",
    "    return qml.expval(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_shift_whole(thetas, phis, x, num_layers):\n",
    "    \"\"\"\n",
    "    Basic Parameter shift rule for each x_i i= 0,1, ..., xdim\n",
    "   \n",
    "    INPUT\n",
    "    qnode :  circuit ansatz we designed\n",
    "    parmas : (array) of parameters we put in the circuit\n",
    "    x_i : (int) ${{\\partial f(\\theta)} \\over {\\partial x_i}}$\n",
    "    phis : (array) the last parameters of the circuit\n",
    "    ndim : (int) dimenstion of $\\vec{x}$\n",
    "    num_layers : (int) number of layer we make for the model\n",
    "\n",
    "    OUTPUT\n",
    "    expectation value where we apply the Basic PSR for the circuit\n",
    "    \"\"\"\n",
    "    thetas_n = toarray(thetas)\n",
    "    phis_n = toarray(phis)\n",
    "\n",
    "    shifted_thetas = thetas_n.copy()\n",
    "    shifted_phis = phis_n.copy()\n",
    "    \n",
    "    shifted_thetas[:] += np.pi/2\n",
    "    shifted_phis[:] += np.pi/2\n",
    "    forward = Ansatz(shifted_thetas, shifted_phis, x, num_layers)  # forward evaluation\n",
    "\n",
    "    shifted_thetas[:] -= np.pi\n",
    "    shifted_phis[:] -= np.pi\n",
    "    backward = Ansatz(shifted_thetas, shifted_phis, x, num_layers) # backward evaluation\n",
    "\n",
    "    return 0.5 * (forward - backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.565075233657859"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss_function(thetas, phis, Xdata, num_layers, target):\n",
    "    \"\"\"\n",
    "    loss function\n",
    "\n",
    "    INPUT\n",
    "    \n",
    "\n",
    "    OUTPUT\n",
    "    loss with MSE\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(Xdata)):\n",
    "        estimated_val = parameter_shift_whole(thetas, phis, Xdata[i], num_layers)\n",
    "        target_val = target[i]\n",
    "\n",
    "        loss += ((estimated_val - target_val) ** 2)\n",
    "\n",
    "    return loss / len(Xdata)\n",
    "\n",
    "xdim = len(Xdata[0])\n",
    "num_layers = 1\n",
    "num_qubits = math.ceil(xdim / 2)\n",
    "\n",
    "thetas = np.random.uniform(size=xdim*num_layers*5, requires_grad=True)\n",
    "phis = np.random.uniform(size = num_qubits, requires_grad =True)\n",
    "    \n",
    "loss_function(thetas, phis, Xdata, num_layers, Ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Runnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_running(thetas, phis, Xdata, num_layers):\n",
    "    \"\"\"\n",
    "    Model running with given set of data.\n",
    "\n",
    "    INPUT\n",
    "    params : array of parameters \n",
    "    phis : array of last RY rotation\n",
    "    Xdata : values of xdata\n",
    "\n",
    "    OUTPU\n",
    "    Expectaion values(Integration value ???), Estimated value(derivative of the circuit)\n",
    "    \"\"\"\n",
    "    exepctation_values = []\n",
    "    estimated_values = []\n",
    "    \n",
    "    params = 0\n",
    "    params += thetas\n",
    "   \n",
    "    for i in range(len(Xdata)):\n",
    "\n",
    "        expval = Ansatz(thetas, phis, Xdata[i], num_layers)\n",
    "        exepctation_values.append(expval)\n",
    "\n",
    "        estimated_val = parameter_shift_whole(thetas, phis, Xdata[i], num_layers)\n",
    "        estimated_values.append(estimated_val)\n",
    "        \n",
    "    return np.array(exepctation_values), np.array(estimated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Accuracy score. Evaluating the model with the label comparing.\n",
    "    \n",
    "    INPUT\n",
    "    y_true : Targets(Answers)\n",
    "    y_predicted : Predictions(labels wihch model has given)\n",
    "\n",
    "    OUTPUT\n",
    "    the fraction of correctly classified samples\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for i in range(len(y_true)):\n",
    "        score += y_pred == y_true \n",
    "\n",
    "    return score.sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batch_size):\n",
    "    \"\"\"\n",
    "    A generator for batches of the input data\n",
    "    \n",
    "    INPUT\n",
    "    inputs : input data\n",
    "    targets : targets\n",
    "    batch_size : size of the batch, the number of datas in one batch\n",
    "\n",
    "    Returns\n",
    "    one batch of input data of length `batch_size`, one batch of targets of length `batch_size`\n",
    "    \"\"\"\n",
    "    for start_idx in range(0, inputs.shape[0] - batch_size + 1, batch_size):\n",
    "        idxs = slice(start_idx, start_idx + batch_size)\n",
    "        yield inputs[idxs], targets[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.625248 | Train accuracy: -9711.480171 | Test Accuracy: -2108.816133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (9250,) (750,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     thetas, phis, _, _, _ \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mstep(loss_function, thetas, phis, Xbatch, num_layers, ybatch)\n\u001b[1;32m     57\u001b[0m predicted_train, expvals_train \u001b[38;5;241m=\u001b[39m model_running(thetas, phis, test_data, num_layers)\n\u001b[0;32m---> 58\u001b[0m accuracy_train \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(Ansatz, thetas, phis, test_data, xdim, num_layers, test_target)\n\u001b[1;32m     61\u001b[0m predicted_test, expvals_test \u001b[38;5;241m=\u001b[39m model_running(thetas, phis, test_data, num_layers)\n",
      "Cell \u001b[0;32mIn[61], line 14\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_true)):\n\u001b[0;32m---> 14\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pennylane/numpy/tensor.py:155\u001b[0m, in \u001b[0;36mtensor.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m args \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39munwrap() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munwrap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# call the ndarray.__array_ufunc__ method to compute the result\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# of the vectorized ufunc\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, Operator):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (9250,) (750,) "
     ]
    }
   ],
   "source": [
    "data = np.load('toy_data_10e4.npz')\n",
    "Xdata = data['xdata']\n",
    "Ydata = data['ydata']\n",
    "\n",
    "#Dividing the trainin data and test data\n",
    "train_data = Xdata[:750]\n",
    "train_target = Ydata[:750]\n",
    "test_data = Xdata[750:]\n",
    "test_target = Ydata[750:]\n",
    "\n",
    "# Checking the data\n",
    "xdim = len(Xdata[0])\n",
    "num_qubits = math.ceil(xdim / 2)\n",
    "\n",
    "# Trainnig option settings\n",
    "num_layers = 1\n",
    "epochs = 25\n",
    "batch_size = 50\n",
    "eta = 0.1\n",
    "\n",
    "# Using the Optimizer\n",
    "opt = AdamOptimizer(stepsize = eta)\n",
    "\n",
    "# Initializing random parameters for the circuit\n",
    "thetas = np.random.uniform(size=xdim*num_layers*5, requires_grad=True)\n",
    "phis = np.random.uniform(size = num_qubits, requires_grad =True)\n",
    "\n",
    "### Evaluating the qNN\n",
    "# Running the model with test data\n",
    "expvals_train, predicted_train = model_running(thetas, phis, train_data, num_layers)\n",
    "accuracy_train = accuracy_score(train_target, predicted_train)\n",
    "\n",
    "# Running the model with the test data\n",
    "expvals_test, predicted_test = model_running(thetas, phis, test_data, num_layers)\n",
    "accuracy_test = accuracy_score(test_target, predicted_test)\n",
    "\n",
    "# Saving predictions with random weights for comparison \n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = loss_function(thetas, phis, test_data, num_layers, test_target)\n",
    "\n",
    "loss_list, accuracy_train_list, accuracy_test_list = [], [], []\n",
    "loss_list.append(loss)\n",
    "accuracy_train_list.append(accuracy_train)\n",
    "accuracy_test_list.append(accuracy_test)\n",
    "\n",
    "print(\n",
    "    \"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(\n",
    "        0, loss, accuracy_train, accuracy_test\n",
    "    )\n",
    ")\n",
    "\n",
    "for it in range(epochs):\n",
    "    for Xbatch, ybatch in iterate_minibatches(train_data, train_target, batch_size=batch_size):\n",
    "        thetas, phis, _, _, _ = opt.step(loss_function, thetas, phis, Xbatch, num_layers, ybatch)\n",
    "\n",
    "    predicted_train, expvals_train = model_running(thetas, phis, test_data, num_layers)\n",
    "    accuracy_train = accuracy_score(train_target, predicted_train)\n",
    "    loss = loss_function(Ansatz, thetas, phis, test_data, xdim, num_layers, test_target)\n",
    "\n",
    "    predicted_test, expvals_test = model_running(thetas, phis, test_data, num_layers)\n",
    "    accuracy_test = accuracy_score(test_target, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\n",
    "        \"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(\n",
    "            *res\n",
    "        )\n",
    "    )\n",
    "\n",
    "    loss_list.append(loss)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
